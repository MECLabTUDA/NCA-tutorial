{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "867413b1",
   "metadata": {},
   "source": [
    "# Classification Task: Classification NCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147ae2b1",
   "metadata": {},
   "source": [
    "Neural Cellular Automata (NCA) offer a novel approach to image classification. Unlike conventional deep learning methods, NCA processes information locally while still capturing local patterns through intercellular communication. Moreover, its local architecture ensures lightweight storage and fast inference while also maintaining robustness to domain shifts.\n",
    "\n",
    "Instead of generating a target image as in Growing NCA, a Classification NCA extracts features of an image to put it into a category. It does not start from a seed, but rather from an input image whose state evolves over several NCA updates.\n",
    "\n",
    "In this notebook, we demonstrate the use of NCAs for classifiying blood cell images from the Matek-19 dataset, a medical dataset containing multiple classes of white blood cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cd56b2",
   "metadata": {},
   "source": [
    "## Implementation Overview\n",
    "\n",
    "Our simplified NCA classification pipeline consists of:\n",
    "\n",
    "1. **NCA Architecture**: Defining the architecure of the Classification NCA model\n",
    "2. **Data Preparation**: Loading and preprocessing the Matek-19 dataset\n",
    "3. **Loss Function**: Binary cross-entropy loss for multi-class classification\n",
    "4. **Training and Evaluation Loop**: Iteratively performing update steps to extract features, which will then be used for classification.\n",
    "5. **Visualization**: Evaluating and visualizing the performance of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68112c71",
   "metadata": {},
   "source": [
    "## 0. Imports & Select Device\n",
    "\n",
    "We start by importing the necessary libraries for our next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b431f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import kagglehub\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "from collections import Counter\n",
    "\n",
    "from shutil import copytree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc1ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db247f",
   "metadata": {},
   "source": [
    "## 1. NCA Architecture \n",
    "\n",
    "It is time to define the NCA model that we will be using - the MaxNCA. The MaxNCA is a Neural Cellular Automata model adapted for image classification, which works by iteratevely updating padded images to extract the channel-wise maximum, thus aggregating the features of an image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7210e99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxNCA(nn.Module):\n",
    "    def __init__(self, channel_n=16, fire_rate=0.5, device=None, hidden_size=128, input_channels=3, init_method=\"standard\"):\n",
    "        \"\"\"Neural Cellular Automata for classification using max-pooling features\n",
    "        \n",
    "        Args:\n",
    "            channel_n: Number of channels in NCA state\n",
    "            fire_rate: Probability of cell updates\n",
    "            device: Device to run computations on\n",
    "            hidden_size: Size of hidden layer in update network\n",
    "            input_channels: Number of input channels\n",
    "            init_method: Weight initialization method ('standard')\n",
    "        \"\"\"\n",
    "        super(MaxNCA, self).__init__()\n",
    "        \n",
    "        # Device configuration  \n",
    "        if device is not None:\n",
    "            self.device = device\n",
    "        else:\n",
    "            self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Model parameters\n",
    "        self.channel_n = channel_n\n",
    "        self.input_channels = input_channels\n",
    "        self.fire_rate = fire_rate\n",
    "\n",
    "        # Two depthwise convolutional layers to capture patterns\n",
    "        self.p0 = nn.Conv2d(channel_n, channel_n, kernel_size=3, stride=1, padding=1, groups = channel_n, padding_mode=\"reflect\")\n",
    "        self.p1 = nn.Conv2d(channel_n, channel_n, kernel_size=3, stride=1, padding=1, groups = channel_n, padding_mode=\"reflect\")\n",
    "\n",
    "        # Processes neighborhood information to determine cell updates\n",
    "        self.fc0 = nn.Conv2d(channel_n*3, hidden_size, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(hidden_size, track_running_stats=False)\n",
    "        self.fc1 = nn.Conv2d(hidden_size, channel_n, kernel_size=1, bias=False)\n",
    "\n",
    "\n",
    "        # Takes final NCA state and classifies it into one of 13 categories\n",
    "        self.fc2 = nn.Linear(channel_n,128)\n",
    "        self.fc3 = nn.Linear(128,13)\n",
    "\n",
    "        # Initialize last layer to zero\n",
    "        with torch.no_grad():\n",
    "            self.fc1.weight.zero_()\n",
    "\n",
    "    def perceive(self, x):\n",
    "        \"\"\"Creates perception vector\n",
    "\n",
    "        Args:\n",
    "            x: current state\n",
    "        \"\"\"\n",
    "        z1 = self.p0(x)\n",
    "        z2 = self.p1(x)\n",
    "        y = torch.cat((x,z1,z2),1)\n",
    "        return y\n",
    "\n",
    "    def update(self, x_in, fire_rate):\n",
    "        \"\"\"Performs one NCA update step\n",
    "\n",
    "        Args:\n",
    "            x: Input state tensor [B,H,W,C]\n",
    "            fire_rate: Update probability \n",
    "        \"\"\"\n",
    "        # Transpose for linear layers [B,C,H,W] -> [B,H,W,C]\n",
    "        x = x_in.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Compute updates\n",
    "        dx = self.perceive(x)\n",
    "        dx = self.fc0(dx)\n",
    "        dx = self.bn(dx)\n",
    "        dx = F.relu(dx)\n",
    "        dx = self.fc1(dx)\n",
    "\n",
    "        # Stochastic updates\n",
    "        if fire_rate is None:\n",
    "            fire_rate = self.fire_rate\n",
    "        stochastic = (torch.rand((dx.size(0), 1, dx.size(2), dx.size(3)), device=x.device) > fire_rate).float()\n",
    "        dx = dx * stochastic\n",
    "\n",
    "        # Apply updates\n",
    "        x = x + dx\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, steps=32, fire_rate=0.5):\n",
    "        \"\"\"Forward function, applies k NCA update steps leaving input channels unchanged\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor [B,H,W,C]\n",
    "            steps: Number of NCA updates\n",
    "            fire_rate: Update probability\n",
    "        \"\"\"\n",
    "        # NCA update steps\n",
    "        for step in range(steps):\n",
    "            x2 = self.update(x, fire_rate).clone()\n",
    "            x = torch.concat((x[...,:self.input_channels], x2[...,self.input_channels:]), 3)\n",
    "        \n",
    "        # Feature Aggregation\n",
    "        max=F.adaptive_max_pool2d(x.permute(0, 3, 1, 2), (1, 1))\n",
    "        max = max.view(max.size(0), -1)\n",
    "        \n",
    "        # Classification\n",
    "        out=self.fc2(max)\n",
    "        out = F.relu(out)\n",
    "        out =self.fc3(out)\n",
    "        \n",
    "        return out,x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7ef7b4",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6a659c",
   "metadata": {},
   "source": [
    "### 2.1 Dataloader\n",
    "\n",
    "Now we need to define a dataset that handles our classification task. The WBC_Dataset is just what we need to manage the white blood cell (WBC) images of the Matek-19 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27881fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class WBC_Dataset(data.Dataset):\n",
    "    \"\"\"PyTorch Dataset for White Blood Cell (WBC) images with augmentation support\"\"\"\n",
    "    def __init__(self,image_paths,labels,resize=None, augment=False, dataset=\"AML\"):\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.image_paths=image_paths\n",
    "        self.labels=labels\n",
    "        self.resize=resize # Number of pixels in one dimension (square image)\n",
    "        self.augment=augment\n",
    "        self.transforms = v2.Compose([\n",
    "            v2.RandomRotation([0,360]),\n",
    "            v2.RandomHorizontalFlip(p=0.5),\n",
    "            ])\n",
    "        \n",
    "        self.norm = v2.Compose([v2.ToTensor(), v2.Normalize(mean=[0.82069695, 0.7281261, 0.836143],std=[0.16157213, 0.2490039, 0.09052657])])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image = Image.open(self.image_paths[idx])\n",
    "        if self.resize is not None:\n",
    "            image=image.resize((self.resize,self.resize))\n",
    "        image=np.array(image)[:,:,0:3]\n",
    "        if self.augment:\n",
    "            image = self.transforms(image)\n",
    "            \n",
    "        image=self.norm(image)\n",
    "        label=torch.zeros(13)\n",
    "        label[self.labels[idx]]=1\n",
    "\n",
    "        return image.permute(1,2,0), label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7444cda5",
   "metadata": {},
   "source": [
    "### 2.2 Downloading the dataset\n",
    "\n",
    "We will be using the Matek-19, a public dataset containing over 18,000 annotated blood cells from 200 individuals. Half of those subjects are affected by AML.\n",
    "\n",
    "You can find the dataset we used here: [Matek-19 Dataset](https://www.kaggle.com/datasets/inhvnnhn/matek-19-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284fafe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset using Kaggle Hub API\n",
    "download_path = kagglehub.dataset_download(\"inhvnnhn/matek-19-dataset\")\n",
    "# Copy dataset to a working directory\n",
    "copytree(os.path.join(download_path, \"Matek-19 Dataset\"), \n",
    "                \"INSERT/input/Matek19\",\n",
    "                dirs_exist_ok=True)\n",
    "matek19_path = \"INSERT/input/Matek19\" # Set dataset path for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8790a82",
   "metadata": {},
   "source": [
    "### 2.3 Data Preparation\n",
    "\n",
    "We prepare our dataset by creating iterable batches of processed images and labels from the raw dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb60dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# White Blood Cell (WBC) class names\n",
    "CLASSES = ['basophil','eosinophil','erythroblast','myeloblast','promyelocyte','myelocyte','metamyelocyte','neutrophil_banded','neutrophil_segmented','monocyte','lymphocyte_typical','lymphocyte_atypical','smudge_cell']\n",
    "\n",
    "\n",
    "def plot_distribution(labels, output_path):\n",
    "    \"\"\"Visualize and save class distribution of the dataset\n",
    "\n",
    "    Args:\n",
    "        labels: List of integer class labels\n",
    "        output_pat: Path to save the distribution plot\n",
    "    \"\"\"\n",
    "    counts =[Counter(labels)[i] for i in range(13)] # Count samples per class\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(CLASSES, counts)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Number of Samples\")\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "def get_data_AML(data_path,show_distribution=True):\n",
    "    \"\"\"Loads WBC image paths and labels from AML dataset\n",
    "\n",
    "    Args:\n",
    "        data_path: Path to dataset directory\n",
    "        show_distribution: Whether to plot class distribution\n",
    "    \"\"\"\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for dirs in os.listdir(data_path):\n",
    "        folder_path = os.path.join(data_path, dirs)\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith('.jpg') or file.endswith('.tiff'):\n",
    "                image_path = os.path.join(folder_path, file)\n",
    "                \n",
    "                if \"BAS\" in file:\n",
    "                    label = 0\n",
    "                elif \"EBO\" in file:\n",
    "                    label = 2\n",
    "                elif \"EOS\" in file:\n",
    "                    label = 1\n",
    "                elif \"KSC\" in file:\n",
    "                    label = 12\n",
    "                elif \"LYA\" in file:\n",
    "                    label = 11\n",
    "                elif \"LYT\" in file:\n",
    "                    label = 10\n",
    "                elif \"MMZ\" in file:\n",
    "                    label = 6\n",
    "                elif \"MOB\" in file:\n",
    "                    label = 9\n",
    "                elif \"MON\" in file:\n",
    "                    label = 9\n",
    "                elif \"MYB\" in file:\n",
    "                    label = 5\n",
    "                elif \"MYO\" in file:\n",
    "                    label = 3\n",
    "                elif \"NGB\" in file:\n",
    "                    label = 7\n",
    "                elif \"NGS\" in file:\n",
    "                    label = 8\n",
    "                elif \"PMB\" in file:\n",
    "                    label = 4\n",
    "                elif \"PMO\" in file:\n",
    "                    label = 4\n",
    "                labels.append(label)\n",
    "                image_paths.append(image_path)\n",
    "        \n",
    "    if show_distribution==True:\n",
    "        plot_distribution(labels, \"INSERT/output/data_distribution_AML.png\")\n",
    "\n",
    "    return image_paths, labels\n",
    "\n",
    "def get_weights(y):\n",
    "    \"\"\"Calculate class weights for imbalanced dataset handling\n",
    "\n",
    "    Args:\n",
    "        y: List of integer class labels\n",
    "    \"\"\"\n",
    "    class_counts = Counter(y)\n",
    "    class_counts = np.array([class_counts[i] for i in range(15)])\n",
    "    class_weights = 1/(class_counts+0.001) # Avoid division by zero\n",
    "    sample_weights = [class_weights[i] for i in y]\n",
    "    return sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea7d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data_path):\n",
    "    \"\"\"Prepares WBC image data for training\"\"\"\n",
    "\n",
    "    # Load image paths and labels from dataset\n",
    "    x, y = get_data_AML(data_path, show_distribution=False)\n",
    "    x_np = np.asarray(x)\n",
    "    y_np = np.asarray(y)\n",
    "\n",
    "    # Split data into training and validation sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_np, y_np, test_size=0.20, random_state=2)\n",
    "\n",
    "    # Create Pytorch datasets\n",
    "    train_dataset = WBC_Dataset(x_train, y_train, augment=True, resize=64, dataset=\"AML\")\n",
    "    val_dataset = WBC_Dataset(x_test, y_test, resize=64, dataset=\"AML\")\n",
    "\n",
    "    # Create sampler for balanced sampling\n",
    "    sampler = data.WeightedRandomSampler(weights=get_weights(y_train), num_samples=len(train_dataset), replacement=True)\n",
    "\n",
    "    # Create data loaders for efficient batch loading\n",
    "    train_loader = data.DataLoader(train_dataset,sampler=sampler,batch_size=32)\n",
    "    val_loader = data.DataLoader(val_dataset, batch_size=1)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7946b4b3",
   "metadata": {},
   "source": [
    "## 3. Loss Function\n",
    "\n",
    "It is time to implement the loss function. We implement the Binary Cross-Entropy loss function to classify the images into different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb2532",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCELoss(torch.nn.Module):\n",
    "    \"\"\"Binary Cross-Entropy Loss with optional sigmoid activation\"\"\"\n",
    "    def __init__(self, useSigmoid = True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            useSigmoid: Whether to use sigmoid\n",
    "        \"\"\"\n",
    "        self.useSigmoid = useSigmoid\n",
    "        super(BCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target, smooth=1):\n",
    "        \"\"\"Forward function\n",
    "\n",
    "        Args:\n",
    "            input: input array\n",
    "            target: target array\n",
    "            smooth: Smoothing value\n",
    "        \"\"\"\n",
    "        input = torch.sigmoid(input)       \n",
    "        input = torch.flatten(input) \n",
    "        target = torch.flatten(target)\n",
    "\n",
    "        BCE = torch.nn.functional.binary_cross_entropy(input.float(), target.float(), reduction='mean')\n",
    "        return BCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39e0f0e",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluation Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9cede9",
   "metadata": {},
   "source": [
    "![alt text](../assets/model_graphic.svg)[Source](https://github.com/marrlab/WBC-NCA/blob/main/src/images/model_graphic.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bce0f8",
   "metadata": {},
   "source": [
    "The training process follows four main steps:\n",
    "1. **Image Padding**: We pad the images to the desired amount of channels. These additional hidden channels are initialized to zero.\n",
    "\n",
    "2. **NCA Update Steps**: The model performs k iterative NCA update steps to extract features.\n",
    "\n",
    "3. **Feature Aggregation**: The model takes each channels maximum to condense the evolved state into a compact feature vector.\n",
    "\n",
    "4. **Classification**: Lastly, this feature vector is used as an input for our neural network, which will then predict the class of the image.\n",
    "\n",
    "Here we have combined the training and evaluation of the model into a single loop. For the training we use an Adam optimizer with a learning rate of 0.0004, following the setup in the original paper.\n",
    "\n",
    "Evaluation is performed after each epoch to compute validation loss, accuracy, and the F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c10e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nca():\n",
    "    \"\"\"Trains and evaluates MaxNCA model\"\"\"\n",
    "\n",
    "    # 1. Model Initilization\n",
    "    model=MaxNCA(channel_n=16, hidden_size=128, device=device)\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0004) #Adam optimizer\n",
    "    loss_f = BCELoss() #Binary Cross-Entropy\n",
    "\n",
    "    # 2. Data Preparation\n",
    "    train_loader, val_loader = prepare_data(matek19_path)\n",
    "\n",
    "    # Initialize metrics storage\n",
    "    train_loss_total = np.zeros(5)\n",
    "    val_loss_total = np.zeros(5)\n",
    "    accuracy_list = []\n",
    "    f1_list = []\n",
    "    \n",
    "    # 3. Training & Evaluation Loop (5 Epochs)\n",
    "    for epoch in range(5):\n",
    "        # 3.1 Training Phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            # Load data to device\n",
    "            inputs, targets = batch\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Prepare NCA initial state  \n",
    "            seed = torch.zeros(inputs.shape[0], 64, 64, 16).to(device)\n",
    "            seed[..., :3] = inputs  #RGB Padding\n",
    "\n",
    "            # Forward pass with 12 NCA updates\n",
    "            output,_ = model(seed, steps=12, fire_rate=0.5)\n",
    "\n",
    "            # Compute and backpropagate loss\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_f(output.to(device),targets.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()   \n",
    "\n",
    "            train_loss += loss.item()\n",
    "        # Calculate average training loss\n",
    "        train_loss_avg = train_loss/len(train_loader)\n",
    "        train_loss_total[epoch]=train_loss_avg\n",
    "\n",
    "        \n",
    "        # 3.2 Validation Phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                # Load data\n",
    "                inputs, targets = batch\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                # Prepare and run NCA\n",
    "                seed = torch.zeros(inputs.shape[0], 64, 64, 16).to(device)\n",
    "                seed[..., :3] = inputs  #RGB Padding\n",
    "                output,_ = model(seed, steps=12, fire_rate=0.5)\n",
    "\n",
    "                # Calculate validation loss\n",
    "                val_loss += loss_f(output.to(device),targets.to(device))\n",
    "\n",
    "                # Store predictions and labels for metrics\n",
    "                preds = torch.argmax(output, dim=1)\n",
    "                labels = torch.argmax(targets, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Calculate validation metrics\n",
    "        val_loss_avg = val_loss/len(val_loader)\n",
    "        val_loss_total[epoch] = val_loss_avg.item()\n",
    "\n",
    "        # Compute accuracy and F1 score\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "        accuracy_list.append(accuracy)\n",
    "        f1_list.append(f1)\n",
    "        \n",
    "        # 3.3 Showcase training and validation results\n",
    "        print(f\"Epoch {epoch+1}/{5} | \"\n",
    "              f\"Train Loss: {train_loss_avg:.4f} | \"\n",
    "              f\"Val Loss: {val_loss_avg:.4f} | \"\n",
    "              f\"Accuracy: {accuracy:.4f} | \"\n",
    "              f\"F1 Score: {f1:.4f}\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    # 4. Save model\n",
    "    model_dir = \"INSERT/models\"\n",
    "    model_path = os.path.join(model_dir, \"MaxNCA.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    return model, train_loss_total, val_loss_total, accuracy_list, f1_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1889d258",
   "metadata": {},
   "source": [
    "### Finally, run the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916376f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    model, train_loss_total, val_loss_total, accuracy_list, f1_list= train_nca()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f0f7f3",
   "metadata": {},
   "source": [
    "## 5. Visualization\n",
    "\n",
    "This step is optional, however it may help understanding and analyzing the results of the model.\n",
    "We plot the following metrics:\n",
    "* Training loss & validation loss\n",
    "* Accuracy score & F1 score\n",
    "* Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467890bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train,val,dataset):\n",
    "    \"\"\"Plot training and validation loss over epochs\"\"\"\n",
    "    fig=plt.figure()\n",
    "    plt.rcParams['figure.figsize'] = [5, 5]\n",
    "    plt.plot(train, label=\"Train\")\n",
    "    plt.plot(val, label=\"Val\")\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')    \n",
    "    plt.savefig(\"INSERT/output/loss_plot_\"+dataset+\".png\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f85896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training and validation loss\n",
    "plot_loss(train_loss_total,val_loss_total,\"MaxNCA - Train & Val Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce014d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(accuracy_list,f1_list,dataset):\n",
    "    \"\"\"Plot accuracy and F1 score over epochs\"\"\"\n",
    "    fig=plt.figure()\n",
    "    plt.rcParams['figure.figsize'] = [5, 5]\n",
    "    plt.plot(accuracy_list, label=\"Accuracy\")\n",
    "    plt.plot(f1_list, label=\"F1 Score\")\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    \n",
    "    plt.savefig(\"INSERT/output/loss_plot_\"+dataset+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09b9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize accuracy and F1 score\n",
    "plot_metrics(accuracy_list, f1_list,\"MaxNCA - Accuracy & F1-Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a98181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(model, test_loader, steps, dataset_name):\n",
    "    \"\"\"Compute and display confusion matrix\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs,targets in test_loader:\n",
    "            seed = torch.zeros(inputs.shape[0], 64, 64, 16).to(model.device)\n",
    "            seed[..., :3] = inputs\n",
    "\n",
    "            outputs, _ = model(seed, steps=steps, fire_rate=0.5)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            labels = torch.argmax(targets, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "    confusion_matrix = metrics.confusion_matrix(all_labels, all_preds)\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix,  display_labels=[str(i) for i in range(13)])\n",
    "\n",
    "    cm_display.plot()\n",
    "    plt.title(f\"Confusion Matrix - {dataset_name}\")\n",
    "    plt.savefig(f\"/INSERT/output/confusion_matrix_{dataset_name}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a583bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, val_loader = prepare_data(matek19_path)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "confusionMatrix(model, val_loader, steps=12, dataset_name=\"matek19\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
